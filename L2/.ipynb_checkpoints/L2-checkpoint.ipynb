{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e42966f-5b62-4b86-84ce-b5de85098e64",
   "metadata": {},
   "source": [
    "# L2: Interactive AI Applications: Building a Simple AI Role Playing Game (RPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3061918c-6bb2-4db0-a061-10fb3cb688fe",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> ðŸš¨\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by AI models can vary with each execution due to their dynamic, probabilistic nature. Don't be surprised if your results differ from those shown in the video.<br>\n",
    "<span style=\"font-size: larger;\">To maintain consistency, the notebooks are run with a 'world state' consistent with the video at the start of each notebook.</span></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dceeb2-b82b-4759-ad62-da5a9a1253f6",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> ðŸ’» &nbsp; <b>Access <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>.\n",
    "\n",
    "<p> â¬‡ &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "<p> ðŸ“’ &nbsp; For more help, please see the <em>\"Appendix â€“ Tips, Help, and Download\"</em> Lesson.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d851be-0eda-48eb-92d3-3c59b31b0159",
   "metadata": {},
   "source": [
    "## Create a Game UI with Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2e37b6e-e683-4a99-93ec-8ff0ab9528a2",
   "metadata": {
    "height": 538,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://0.0.0.0:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "demo = None #added to allow restart\n",
    "\n",
    "def start_game(main_loop, share=False):\n",
    "    # added code to support restart\n",
    "    global demo\n",
    "    # If demo is already running, close it first\n",
    "    if demo is not None:\n",
    "        demo.close()\n",
    "\n",
    "    demo = gr.ChatInterface(\n",
    "        main_loop,\n",
    "        chatbot=gr.Chatbot(height=250, placeholder=\"Type 'start game' to begin\"),\n",
    "        textbox=gr.Textbox(placeholder=\"What do you do next?\", container=False, scale=7),\n",
    "        title=\"AI GAME\",\n",
    "        # description=\"Ask Yes Man any question\",\n",
    "        theme=\"soft\",\n",
    "        examples=[\"Look around\", \"Continue the story\"],\n",
    "        cache_examples=False,\n",
    "        retry_btn=\"Retry\",\n",
    "        undo_btn=\"Undo\",\n",
    "        clear_btn=\"Clear\",\n",
    "                           )\n",
    "    demo.launch(share=share, server_name=\"0.0.0.0\")\n",
    "\n",
    "def test_main_loop(message, history):\n",
    "    return 'Entered Action: ' + message\n",
    "\n",
    "start_game(test_main_loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4bb323-dbaf-4705-b884-548331b1dd8b",
   "metadata": {},
   "source": [
    "## Generating an Initial Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "407506d5-5745-4116-9c12-77d5f3789dff",
   "metadata": {
    "height": 198
   },
   "outputs": [],
   "source": [
    "from helper import load_world, save_world\n",
    "from together import Together\n",
    "from helper import get_together_api_key, load_env\n",
    "\n",
    "client = Together(api_key=get_together_api_key())\n",
    "\n",
    "world = load_world('D:\\DLprojects\\AIpoweredgame\\L1\\MyWorld_L1.json')\n",
    "kingdom = world['kingdoms']['Eldrida']\n",
    "town = kingdom['towns'][\"Luminaria\"]\n",
    "character = town['npcs']['Thrain Stonefist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61cc045d-e085-4c1d-8c95-34af2461c3d7",
   "metadata": {
    "height": 283
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are an AI Game master. Your job is to create a \n",
    "start to an adventure based on the world, kingdom, town and character \n",
    "a player is playing as. \n",
    "Instructions:\n",
    "You must only use 2-4 sentences \\\n",
    "Write in second person. For example: \"You are Jack\" \\\n",
    "Write in present tense. For example \"You stand at...\" \\\n",
    "First describe the character and their backstory. \\\n",
    "Then describes where they start and what they see around them.\"\"\"\n",
    "world_info = f\"\"\"\n",
    "World: {world}\n",
    "Kingdom: {kingdom}\n",
    "Town: {town}\n",
    "Your Character: {character}\n",
    "\"\"\"\n",
    "#not run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5102a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are an AI Game Master. Your role is to guide the player into an immersive adventure based on the world, kingdom, town, and character they are playing as.  \n",
    "\n",
    "### Instructions:  \n",
    "- Write **only 2-4 sentences** to introduce the adventure.  \n",
    "- Use **second person** perspective (e.g., \"You are Jack\").  \n",
    "- Use **present tense** (e.g., \"You stand at the gates of the city...\").  \n",
    "- **Start with the character's description and backstory** to establish their identity.  \n",
    "- **Describe their current location and surroundings**, setting the tone for their journey.  \n",
    "- Create an **atmospheric and engaging** opening that invites exploration and decision-making.  \n",
    "\"\"\"  \n",
    "\n",
    "world_info = f\"\"\"\n",
    "World: {world}  \n",
    "Kingdom: {kingdom}  \n",
    "Town: {town}  \n",
    "Your Character: {character}  \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e4b36dc-03c6-4729-8530-1924ce3739e0",
   "metadata": {
    "height": 181
   },
   "outputs": [
    {
     "ename": "APIError",
     "evalue": "Error code: 422 - {\"message\": \"Input validation error: `inputs` tokens + `max_new_tokens` must be <= 8193. Given: 7439 `inputs` tokens and 2048 `max_new_tokens`\", \"type_\": \"invalid_request_error\", \"param\": null, \"code\": null}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_output \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta-llama/Llama-3-70b-chat-hf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mworld_info\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mYour Start:\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\together\\resources\\chat\\completions.py:136\u001b[0m, in \u001b[0;36mChatCompletions.create\u001b[1;34m(self, messages, model, max_tokens, stop, temperature, top_p, top_k, repetition_penalty, presence_penalty, frequency_penalty, min_p, logit_bias, stream, logprobs, echo, n, safety_model, response_format, tools, tool_choice)\u001b[0m\n\u001b[0;32m    109\u001b[0m requestor \u001b[38;5;241m=\u001b[39m api_requestor\u001b[38;5;241m.\u001b[39mAPIRequestor(\n\u001b[0;32m    110\u001b[0m     client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client,\n\u001b[0;32m    111\u001b[0m )\n\u001b[0;32m    113\u001b[0m parameter_payload \u001b[38;5;241m=\u001b[39m ChatCompletionRequest(\n\u001b[0;32m    114\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    115\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    133\u001b[0m     tool_choice\u001b[38;5;241m=\u001b[39mtool_choice,\n\u001b[0;32m    134\u001b[0m )\u001b[38;5;241m.\u001b[39mmodel_dump()\n\u001b[1;32m--> 136\u001b[0m response, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTogetherRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameter_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, TogetherResponse)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\together\\abstract\\api_requestor.py:249\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, options, stream, remaining_retries, request_timeout)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    233\u001b[0m     options: TogetherRequest,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    241\u001b[0m ]:\n\u001b[0;32m    242\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    243\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    244\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries,\n\u001b[0;32m    245\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    246\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    247\u001b[0m     )\n\u001b[1;32m--> 249\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\together\\abstract\\api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    613\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    614\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    615\u001b[0m         )\n\u001b[0;32m    616\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    617\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 620\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    626\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    627\u001b[0m     )\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\together\\abstract\\api_requestor.py:689\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;66;03m# Handle streaming errors\u001b[39;00m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 689\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(resp, rcode, stream_error\u001b[38;5;241m=\u001b[39mstream)\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mAPIError\u001b[0m: Error code: 422 - {\"message\": \"Input validation error: `inputs` tokens + `max_new_tokens` must be <= 8193. Given: 7439 `inputs` tokens and 2048 `max_new_tokens`\", \"type_\": \"invalid_request_error\", \"param\": null, \"code\": null}"
     ]
    }
   ],
   "source": [
    "model_output = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-3-70b-chat-hf\",\n",
    "    temperature=1.0,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": world_info + '\\nYour Start:'}\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88890d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-3-70b-chat-hf\",\n",
    "    temperature=0.8,  # Slightly lower for more controlled output\n",
    "    max_tokens=1024,  # Reduce max tokens to prevent exceeding limit\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt[:2000]},  # Trim system prompt if needed\n",
    "        {\"role\": \"user\", \"content\": (world_info[:5000] + '\\nYour Start:')},  # Trim world_info\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5848ae81-b140-4256-a827-d8f3dc618966",
   "metadata": {
    "height": 113
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are Kaida Blackwood, a 25-year-old skilled crystal engineer with a passion for innovation and a reputation for recklessness. You stand in the heart of Luminaria, surrounded by the town's famous crystal formations that refract and reflect the light of the Landstriders. The air is alive with the hum of magic and the whispers of the crystals, drawing you to the next great discovery. As you gaze out at the sprawling city built upon the back of the massive Landstrider, Arkeia, you feel an insatiable hunger to unlock the secrets of the ancient magic that flows through these majestic creatures.\n"
     ]
    }
   ],
   "source": [
    "start = model_output.choices[0].message.content\n",
    "print(start)\n",
    "world['start'] = start\n",
    "#save_world(world, '../shared_data/Kyropeia.json')  # preserve video version\n",
    "save_world(world, 'D:\\DLprojects\\AIpoweredgame\\L1\\MyWorld_L1.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77fc24b-c95e-4b9f-9dc3-c0484316d194",
   "metadata": {},
   "source": [
    "## Creating the Main Action Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a81ec047-6409-401c-a426-7c3982244a5e",
   "metadata": {
    "height": 606
   },
   "outputs": [],
   "source": [
    "def run_action(message, history, game_state):\n",
    "    \n",
    "    if(message == 'start game'):\n",
    "        return game_state['start']\n",
    "\n",
    "    system_prompt = \"\"\"You are an AI Game master. Your job is to write what \\\n",
    "happens next in a player's adventure game.\\\n",
    "Instructions: \\\n",
    "You must on only write 1-3 sentences in response. \\\n",
    "Always write in second person present tense. \\\n",
    "Ex. (You look north and see...)\"\"\"\n",
    "    \n",
    "    world_info = f\"\"\"\n",
    "World: {game_state['world']}\n",
    "Kingdom: {game_state['kingdom']}\n",
    "Town: {game_state['town']}\n",
    "Your Character:  {game_state['character']}\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": world_info}\n",
    "    ]\n",
    "    for action in history:\n",
    "        messages.append({\"role\": \"assistant\", \"content\": action[0]})\n",
    "        messages.append({\"role\": \"user\", \"content\": action[1]})\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "    model_output = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3-70b-chat-hf\",\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    result = model_output.choices[0].message.content\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "129e6ae9-a902-47a8-a1fd-ee3ddb14c909",
   "metadata": {
    "height": 198
   },
   "outputs": [],
   "source": [
    "game_state = {\n",
    "    \"world\": world['description'],\n",
    "    \"kingdom\": kingdom['description'],\n",
    "    \"town\": town['description'],\n",
    "    \"character\": character['description'],\n",
    "    \"start\": start,\n",
    "}\n",
    "\n",
    "def main_loop(message, history):\n",
    "    return run_action(message, history, game_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721df4ad-046a-416f-b7aa-bbeedbdbc09e",
   "metadata": {},
   "source": [
    "## Launch and Share!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a4d444a-cbe3-4d12-882a-5eed56c6b778",
   "metadata": {
    "height": 30,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Running on local URL:  http://0.0.0.0:7860\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_game(main_loop, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64ce71f-30ba-4f6a-909c-dc5507284054",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
